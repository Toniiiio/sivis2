% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sivis.R
\name{check_robotstxt}
\alias{check_robotstxt}
\title{Check allowance to scrape in robotstxt}
\usage{
check_robotstxt(page_url)
}
\arguments{
\item{page_url}{The url on which the data were selected. This is not necessarily the url of the request, but the url on which the content
was shown to the user in the browser.}
}
\value{
Is scraping allowed yes / no.
}
\description{
robots.txt can give an indication whether a host allows a scraping of his website, see \url{https://en.wikipedia.org/wiki/Robots_exclusion_standard}.
It will be checked  whether a robots.txt is present. If the robotstxt disallows scraping the user is given the choice to
interrupt the process.
}
\examples{

check_robotstxt("https://www.r-bloggers.com")

}
